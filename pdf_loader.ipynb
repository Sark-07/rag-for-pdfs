{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c879503",
   "metadata": {},
   "source": [
    "### RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6377b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88a312dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: Pritam_Sarkar_Resume.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: tcs.pdf\n",
      "  ✓ Loaded 3 pages\n",
      "\n",
      "Total documents loaded: 4\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96748c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='INTERNSHIP\\nPROJECTS\\nTECHNICAL SKILLS\\nOTHER ACTIVITIES\\nPRITAM SARKAR\\nhttps://portfolio-pritam.vercel.app | github.com/sark-07 \\nlinkedin.com/in/pritam-sarkar-06208a260 | pritamsarkar.ps07@gmail.com | Phone: +918777721852\\nDeveloped an innovative e-ticketing system for pilgrimage places, effectively mitigating crowd congestion.\\nUtilized React.js to create a dynamic and user-friendly front-end interface. \\nUsed Node.js, Express.js, and MongoDB to establish a robust and efficient back-end infrastructure for data\\nstorage. \\nConstructed a RESTful API and seamlessly integrated Axios to facilitate smooth communication between\\nthe front-end and back-end components.\\nLanguages: Java, Python, JavaScript\\nWeb Development: HTML, CSS, Tailwind CSS, React.js, Node.js, Express.js\\nIDE & Tools: VS code, Google Colab, Figma, Photoshop\\nVersion Control: Git, Github, CI/CD\\nCloud/Databases: MongoDB, MySQL\\nPackages: npm, pip\\nInterests: ML and Generative AI.\\nEDUCATION\\nUniversity of Calcutta Sep 2022 - Present\\nVivekananda College Aug 2019 -  Aug 2022\\nB.Sc (HONS) in Computer Science CGPA: 8.694\\nBarisha Vivekananda High school Jul 2017 -  Jul 2019\\nWBCHSE (XII) Percentage:  81.4\\nMaster of Computer Application Current SGPA: 9.33\\nTEACHING\\nI teach Python programming and basic Web Design to school students.\\nFREELANCE GRAPHIC DESIGNER \\nI design posters, and book covers and have designed book covers for a few publishers like Sikto Kolom, and Inspired\\nWings.\\nCreated a visually appealing sales dashboard interface (Desktop view) for a garment shop, drawing\\ninspiration from dribble designs.\\nUtilized React.js to develop the interface and integrated chart.js to dynamically generate responsive charts,\\neffectively displaying the sales statistics.\\nEmployed tailwind css for sleek and modern styling, enhancing the overall user experience of the\\ndashboard.\\nSalesBoard    \\nTours    \\nDeveloped an image generation tool, modeled after Dall • E, capable of generating images from textual\\nprompts.\\nLeveraged React.js, Tailwind CSS, and Node.js to develop a robust and user-friendly interface.\\nSeamlessly integrated with Stability-AI/sdxl API to generate stunning images accurately aligned with user\\nprompts.\\nEmployed MongoDB as a reliable storage solution for seamless image management and retrieval.\\nDall • E Clone\\nOnlineOasis Infobyte | Web Developer Intern | April 2023 - May 2023\\nDeveloped dynamic web pages using React.js, enhancing user experience and interface.\\nConstructed a custom API using Node.js and Express.js, facilitating seamless data integration.\\nAssessed endpoint functionality through rigorous testing with postman, ensuring robust performance and\\nreliability.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content=\"What is TCS? \\nA part of the Tata group, India's largest mulƟnaƟonal business group and a \\nglobal leader in IT services, consulƟng, and business soluƟons, leverages \\ntechnology for business transformaƟon and helps catalyse change. TCS has \\nover 601,000 of the world's best-trained consultants in 54 countries. The \\ncompany generated consolidated revenues of US$29.1 billion in the ﬁscal year \\nended March 31, 2024, and is listed on the BSE and the NSE in India. \\nChairman \\nNatarajan Chandrasekaran, Chairman of Tata Sons since January 2017, oversees over 100 \\nTata companies with annual revenues exceeding $100 billion. He joined the Board of Tata \\nSons in October 2016. \\nCEO & MD \\nK. Krithivasan is the CEO and Managing Director of Tata Consultancy Services (TCS), a global \\nIT soluƟons ﬁrm. In FY24, TCS generated $29.1 billion in revenue with over 600,000 \\nassociates in 54 countries. \\nDirector \\nO. P BhaƩ. He has served as Chairman, State Bank Group. \\nCFO \\nMr. Samir Seksaria took over as the CFO of Tata Consultancy Services on 1st May 2021. \\nCTO \\nHarrick Vin \\nCOO \\nN. Ganapathy Subramaniam \\n \\nTCS Revenue FY23-24 \\nTCS generated $29.1 billion in revenue with over 614,000 associates in 54 countries. \\nTCS Revenue FY23-24 \\nTCS generated $27.1 billion in revenue with over 600,000 associates in 55 countries. \\nOn Going TCS Projects \\nWBIFMS: Designed, developed, and maintained by Tata Consultancy Service.\"),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='TCS’ products and services are also being enhanced with AI c .. \\n \\nRead more at: \\nCompleted TCS Projects \\nMOT Tower \\nSocar Tower \\nShah Deniz-2 \\nDomains where TCS provide support \\nDrilling Companies, Marine Companies, TelecommunicaƟon Companies, Engineering Companies, \\nConstrucƟon Companies, Agriculture Companies \\nTCS’s rank in world \\nIn India no: 1 and in global no: 8 with 29 billion USD. \\nHead Quarter  \\nMumbai, Founded on 1968. \\nWhy do you want to join TCS? \\nI want to be a part of an organizaƟon who is adding value to the world by \\nbringing changes, and TCS is one of the Prime examples of this. TCS works with \\nover 600, 000 associates in 54 – 55 countries in various domain such as drilling, \\nmarine, telecommunicaƟon, construcƟon, agriculture and many more.  \\nAnd this is possible because TCS or I should rather say the enƟre TATA group, \\norganizaƟon provides trustworthiness, reliability in their work and the numbers \\nproves it.  \\nAnd, also the most important thing is the work culture. And TCS is known for a \\nwork culture where everyone is like a member of the family. \\nWhy should we hire you? \\nWhat are you few achievements that you want to share? \\nWhat are the good qualiƟes of a leader? \\n\\uf0b7 CommunicaƟon: Good leaders are clear and unafraid to address challenges. \\n\\uf0b7 Decision-making: Good leaders can make decisions, especially under pressure.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 Vision: A leader’s vision provides direcƟon and purpose for their team. \\n\\uf0b7 Adaptability: Leaders must adapt to evolving situaƟons and challenges. \\n\\uf0b7 Inﬂuence: InﬂuenƟal leaders inspire others to follow their lead willingly. \\n\\uf0b7 Respect: Respect for all team members, regardless of their role or background, \\nis essenƟal for creaƟng a harmonious and inclusive workplace. \\nWhere do you see yourself in ﬁve years? \\n\"Over the next five years, I want to become an expert in [mention a key area that \\nrelates to the job].  \\nI hope to take a leadership role within the department, share my knowledge, and \\nhelp the company grow. I see myself as an integral part of the team\\'s success.\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fab6b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7b75a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 4 documents into 9 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: INTERNSHIP\n",
      "PROJECTS\n",
      "TECHNICAL SKILLS\n",
      "OTHER ACTIVITIES\n",
      "PRITAM SARKAR\n",
      "https://portfolio-pritam.vercel.app | github.com/sark-07 \n",
      "linkedin.com/in/pritam-sarkar-06208a260 | pritamsarkar.ps07@gmail.com | Ph...\n",
      "Metadata: {'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='INTERNSHIP\\nPROJECTS\\nTECHNICAL SKILLS\\nOTHER ACTIVITIES\\nPRITAM SARKAR\\nhttps://portfolio-pritam.vercel.app | github.com/sark-07 \\nlinkedin.com/in/pritam-sarkar-06208a260 | pritamsarkar.ps07@gmail.com | Phone: +918777721852\\nDeveloped an innovative e-ticketing system for pilgrimage places, effectively mitigating crowd congestion.\\nUtilized React.js to create a dynamic and user-friendly front-end interface. \\nUsed Node.js, Express.js, and MongoDB to establish a robust and efficient back-end infrastructure for data\\nstorage. \\nConstructed a RESTful API and seamlessly integrated Axios to facilitate smooth communication between\\nthe front-end and back-end components.\\nLanguages: Java, Python, JavaScript\\nWeb Development: HTML, CSS, Tailwind CSS, React.js, Node.js, Express.js\\nIDE & Tools: VS code, Google Colab, Figma, Photoshop\\nVersion Control: Git, Github, CI/CD\\nCloud/Databases: MongoDB, MySQL\\nPackages: npm, pip\\nInterests: ML and Generative AI.\\nEDUCATION\\nUniversity of Calcutta Sep 2022 - Present'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='Version Control: Git, Github, CI/CD\\nCloud/Databases: MongoDB, MySQL\\nPackages: npm, pip\\nInterests: ML and Generative AI.\\nEDUCATION\\nUniversity of Calcutta Sep 2022 - Present\\nVivekananda College Aug 2019 -  Aug 2022\\nB.Sc (HONS) in Computer Science CGPA: 8.694\\nBarisha Vivekananda High school Jul 2017 -  Jul 2019\\nWBCHSE (XII) Percentage:  81.4\\nMaster of Computer Application Current SGPA: 9.33\\nTEACHING\\nI teach Python programming and basic Web Design to school students.\\nFREELANCE GRAPHIC DESIGNER \\nI design posters, and book covers and have designed book covers for a few publishers like Sikto Kolom, and Inspired\\nWings.\\nCreated a visually appealing sales dashboard interface (Desktop view) for a garment shop, drawing\\ninspiration from dribble designs.\\nUtilized React.js to develop the interface and integrated chart.js to dynamically generate responsive charts,\\neffectively displaying the sales statistics.'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='inspiration from dribble designs.\\nUtilized React.js to develop the interface and integrated chart.js to dynamically generate responsive charts,\\neffectively displaying the sales statistics.\\nEmployed tailwind css for sleek and modern styling, enhancing the overall user experience of the\\ndashboard.\\nSalesBoard    \\nTours    \\nDeveloped an image generation tool, modeled after Dall • E, capable of generating images from textual\\nprompts.\\nLeveraged React.js, Tailwind CSS, and Node.js to develop a robust and user-friendly interface.\\nSeamlessly integrated with Stability-AI/sdxl API to generate stunning images accurately aligned with user\\nprompts.\\nEmployed MongoDB as a reliable storage solution for seamless image management and retrieval.\\nDall • E Clone\\nOnlineOasis Infobyte | Web Developer Intern | April 2023 - May 2023\\nDeveloped dynamic web pages using React.js, enhancing user experience and interface.\\nConstructed a custom API using Node.js and Express.js, facilitating seamless data integration.'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='Developed dynamic web pages using React.js, enhancing user experience and interface.\\nConstructed a custom API using Node.js and Express.js, facilitating seamless data integration.\\nAssessed endpoint functionality through rigorous testing with postman, ensuring robust performance and\\nreliability.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content=\"What is TCS? \\nA part of the Tata group, India's largest mulƟnaƟonal business group and a \\nglobal leader in IT services, consulƟng, and business soluƟons, leverages \\ntechnology for business transformaƟon and helps catalyse change. TCS has \\nover 601,000 of the world's best-trained consultants in 54 countries. The \\ncompany generated consolidated revenues of US$29.1 billion in the ﬁscal year \\nended March 31, 2024, and is listed on the BSE and the NSE in India. \\nChairman \\nNatarajan Chandrasekaran, Chairman of Tata Sons since January 2017, oversees over 100 \\nTata companies with annual revenues exceeding $100 billion. He joined the Board of Tata \\nSons in October 2016. \\nCEO & MD \\nK. Krithivasan is the CEO and Managing Director of Tata Consultancy Services (TCS), a global \\nIT soluƟons ﬁrm. In FY24, TCS generated $29.1 billion in revenue with over 600,000 \\nassociates in 54 countries. \\nDirector \\nO. P BhaƩ. He has served as Chairman, State Bank Group. \\nCFO\"),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='IT soluƟons ﬁrm. In FY24, TCS generated $29.1 billion in revenue with over 600,000 \\nassociates in 54 countries. \\nDirector \\nO. P BhaƩ. He has served as Chairman, State Bank Group. \\nCFO \\nMr. Samir Seksaria took over as the CFO of Tata Consultancy Services on 1st May 2021. \\nCTO \\nHarrick Vin \\nCOO \\nN. Ganapathy Subramaniam \\n \\nTCS Revenue FY23-24 \\nTCS generated $29.1 billion in revenue with over 614,000 associates in 54 countries. \\nTCS Revenue FY23-24 \\nTCS generated $27.1 billion in revenue with over 600,000 associates in 55 countries. \\nOn Going TCS Projects \\nWBIFMS: Designed, developed, and maintained by Tata Consultancy Service.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='TCS’ products and services are also being enhanced with AI c .. \\n \\nRead more at: \\nCompleted TCS Projects \\nMOT Tower \\nSocar Tower \\nShah Deniz-2 \\nDomains where TCS provide support \\nDrilling Companies, Marine Companies, TelecommunicaƟon Companies, Engineering Companies, \\nConstrucƟon Companies, Agriculture Companies \\nTCS’s rank in world \\nIn India no: 1 and in global no: 8 with 29 billion USD. \\nHead Quarter  \\nMumbai, Founded on 1968. \\nWhy do you want to join TCS? \\nI want to be a part of an organizaƟon who is adding value to the world by \\nbringing changes, and TCS is one of the Prime examples of this. TCS works with \\nover 600, 000 associates in 54 – 55 countries in various domain such as drilling, \\nmarine, telecommunicaƟon, construcƟon, agriculture and many more.  \\nAnd this is possible because TCS or I should rather say the enƟre TATA group, \\norganizaƟon provides trustworthiness, reliability in their work and the numbers \\nproves it.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='And this is possible because TCS or I should rather say the enƟre TATA group, \\norganizaƟon provides trustworthiness, reliability in their work and the numbers \\nproves it.  \\nAnd, also the most important thing is the work culture. And TCS is known for a \\nwork culture where everyone is like a member of the family. \\nWhy should we hire you? \\nWhat are you few achievements that you want to share? \\nWhat are the good qualiƟes of a leader? \\n\\uf0b7 CommunicaƟon: Good leaders are clear and unafraid to address challenges. \\n\\uf0b7 Decision-making: Good leaders can make decisions, especially under pressure.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 Vision: A leader’s vision provides direcƟon and purpose for their team. \\n\\uf0b7 Adaptability: Leaders must adapt to evolving situaƟons and challenges. \\n\\uf0b7 Inﬂuence: InﬂuenƟal leaders inspire others to follow their lead willingly. \\n\\uf0b7 Respect: Respect for all team members, regardless of their role or background, \\nis essenƟal for creaƟng a harmonious and inclusive workplace. \\nWhere do you see yourself in ﬁve years? \\n\"Over the next five years, I want to become an expert in [mention a key area that \\nrelates to the job].  \\nI hope to take a leadership role within the department, share my knowledge, and \\nhelp the company grow. I see myself as an integral part of the team\\'s success.\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe92ea",
   "metadata": {},
   "source": [
    "### embedding And vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ae3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b69af3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "543614c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenAI embedding model: text-embedding-3-large\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x20f5d185e80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using OpenAIEmbeddings\"\"\"\n",
    "    def __init__(self, model_name: str = \"text-embedding-3-large\", dimensions: int = None):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        Args:\n",
    "            model_name: OpenAI model name for embeddings\n",
    "            dimensions: Optional, number of dimensions for the embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.dimensions = dimensions\n",
    "        self.model = self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the OpenAIEmbeddings model\"\"\"\n",
    "        print(f\"Loading OpenAI embedding model: {self.model_name}\")\n",
    "        if self.dimensions:\n",
    "            return OpenAIEmbeddings(model=self.model_name, dimensions=self.dimensions)\n",
    "        else:\n",
    "            return OpenAIEmbeddings(model=self.model_name)\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        # OpenAIEmbeddings returns a list of lists\n",
    "        embeddings = self.model.embed_documents(texts)\n",
    "        embeddings = np.array(embeddings)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "## initialize the embedding manager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c9e3b",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c276d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x20f5d186120>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d5d2c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='INTERNSHIP\\nPROJECTS\\nTECHNICAL SKILLS\\nOTHER ACTIVITIES\\nPRITAM SARKAR\\nhttps://portfolio-pritam.vercel.app | github.com/sark-07 \\nlinkedin.com/in/pritam-sarkar-06208a260 | pritamsarkar.ps07@gmail.com | Phone: +918777721852\\nDeveloped an innovative e-ticketing system for pilgrimage places, effectively mitigating crowd congestion.\\nUtilized React.js to create a dynamic and user-friendly front-end interface. \\nUsed Node.js, Express.js, and MongoDB to establish a robust and efficient back-end infrastructure for data\\nstorage. \\nConstructed a RESTful API and seamlessly integrated Axios to facilitate smooth communication between\\nthe front-end and back-end components.\\nLanguages: Java, Python, JavaScript\\nWeb Development: HTML, CSS, Tailwind CSS, React.js, Node.js, Express.js\\nIDE & Tools: VS code, Google Colab, Figma, Photoshop\\nVersion Control: Git, Github, CI/CD\\nCloud/Databases: MongoDB, MySQL\\nPackages: npm, pip\\nInterests: ML and Generative AI.\\nEDUCATION\\nUniversity of Calcutta Sep 2022 - Present'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='Version Control: Git, Github, CI/CD\\nCloud/Databases: MongoDB, MySQL\\nPackages: npm, pip\\nInterests: ML and Generative AI.\\nEDUCATION\\nUniversity of Calcutta Sep 2022 - Present\\nVivekananda College Aug 2019 -  Aug 2022\\nB.Sc (HONS) in Computer Science CGPA: 8.694\\nBarisha Vivekananda High school Jul 2017 -  Jul 2019\\nWBCHSE (XII) Percentage:  81.4\\nMaster of Computer Application Current SGPA: 9.33\\nTEACHING\\nI teach Python programming and basic Web Design to school students.\\nFREELANCE GRAPHIC DESIGNER \\nI design posters, and book covers and have designed book covers for a few publishers like Sikto Kolom, and Inspired\\nWings.\\nCreated a visually appealing sales dashboard interface (Desktop view) for a garment shop, drawing\\ninspiration from dribble designs.\\nUtilized React.js to develop the interface and integrated chart.js to dynamically generate responsive charts,\\neffectively displaying the sales statistics.'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='inspiration from dribble designs.\\nUtilized React.js to develop the interface and integrated chart.js to dynamically generate responsive charts,\\neffectively displaying the sales statistics.\\nEmployed tailwind css for sleek and modern styling, enhancing the overall user experience of the\\ndashboard.\\nSalesBoard    \\nTours    \\nDeveloped an image generation tool, modeled after Dall • E, capable of generating images from textual\\nprompts.\\nLeveraged React.js, Tailwind CSS, and Node.js to develop a robust and user-friendly interface.\\nSeamlessly integrated with Stability-AI/sdxl API to generate stunning images accurately aligned with user\\nprompts.\\nEmployed MongoDB as a reliable storage solution for seamless image management and retrieval.\\nDall • E Clone\\nOnlineOasis Infobyte | Web Developer Intern | April 2023 - May 2023\\nDeveloped dynamic web pages using React.js, enhancing user experience and interface.\\nConstructed a custom API using Node.js and Express.js, facilitating seamless data integration.'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2024-03-30T06:06:19+00:00', 'moddate': '2024-03-30T06:06:18+00:00', 'keywords': 'DAFtpGfxqMU,BAEGqQL-5cM', 'author': 'Ritviz', 'title': 'Pritam_Sarkar_Resume', 'source': 'data\\\\Pritam_Sarkar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Pritam_Sarkar_Resume.pdf', 'file_type': 'pdf'}, page_content='Developed dynamic web pages using React.js, enhancing user experience and interface.\\nConstructed a custom API using Node.js and Express.js, facilitating seamless data integration.\\nAssessed endpoint functionality through rigorous testing with postman, ensuring robust performance and\\nreliability.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content=\"What is TCS? \\nA part of the Tata group, India's largest mulƟnaƟonal business group and a \\nglobal leader in IT services, consulƟng, and business soluƟons, leverages \\ntechnology for business transformaƟon and helps catalyse change. TCS has \\nover 601,000 of the world's best-trained consultants in 54 countries. The \\ncompany generated consolidated revenues of US$29.1 billion in the ﬁscal year \\nended March 31, 2024, and is listed on the BSE and the NSE in India. \\nChairman \\nNatarajan Chandrasekaran, Chairman of Tata Sons since January 2017, oversees over 100 \\nTata companies with annual revenues exceeding $100 billion. He joined the Board of Tata \\nSons in October 2016. \\nCEO & MD \\nK. Krithivasan is the CEO and Managing Director of Tata Consultancy Services (TCS), a global \\nIT soluƟons ﬁrm. In FY24, TCS generated $29.1 billion in revenue with over 600,000 \\nassociates in 54 countries. \\nDirector \\nO. P BhaƩ. He has served as Chairman, State Bank Group. \\nCFO\"),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='IT soluƟons ﬁrm. In FY24, TCS generated $29.1 billion in revenue with over 600,000 \\nassociates in 54 countries. \\nDirector \\nO. P BhaƩ. He has served as Chairman, State Bank Group. \\nCFO \\nMr. Samir Seksaria took over as the CFO of Tata Consultancy Services on 1st May 2021. \\nCTO \\nHarrick Vin \\nCOO \\nN. Ganapathy Subramaniam \\n \\nTCS Revenue FY23-24 \\nTCS generated $29.1 billion in revenue with over 614,000 associates in 54 countries. \\nTCS Revenue FY23-24 \\nTCS generated $27.1 billion in revenue with over 600,000 associates in 55 countries. \\nOn Going TCS Projects \\nWBIFMS: Designed, developed, and maintained by Tata Consultancy Service.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='TCS’ products and services are also being enhanced with AI c .. \\n \\nRead more at: \\nCompleted TCS Projects \\nMOT Tower \\nSocar Tower \\nShah Deniz-2 \\nDomains where TCS provide support \\nDrilling Companies, Marine Companies, TelecommunicaƟon Companies, Engineering Companies, \\nConstrucƟon Companies, Agriculture Companies \\nTCS’s rank in world \\nIn India no: 1 and in global no: 8 with 29 billion USD. \\nHead Quarter  \\nMumbai, Founded on 1968. \\nWhy do you want to join TCS? \\nI want to be a part of an organizaƟon who is adding value to the world by \\nbringing changes, and TCS is one of the Prime examples of this. TCS works with \\nover 600, 000 associates in 54 – 55 countries in various domain such as drilling, \\nmarine, telecommunicaƟon, construcƟon, agriculture and many more.  \\nAnd this is possible because TCS or I should rather say the enƟre TATA group, \\norganizaƟon provides trustworthiness, reliability in their work and the numbers \\nproves it.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='And this is possible because TCS or I should rather say the enƟre TATA group, \\norganizaƟon provides trustworthiness, reliability in their work and the numbers \\nproves it.  \\nAnd, also the most important thing is the work culture. And TCS is known for a \\nwork culture where everyone is like a member of the family. \\nWhy should we hire you? \\nWhat are you few achievements that you want to share? \\nWhat are the good qualiƟes of a leader? \\n\\uf0b7 CommunicaƟon: Good leaders are clear and unafraid to address challenges. \\n\\uf0b7 Decision-making: Good leaders can make decisions, especially under pressure.'),\n",
       " Document(metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-09-25T23:24:22+05:30', 'author': '', 'moddate': '2025-09-25T23:24:22+05:30', 'title': 'Microsoft Word - Chairman', 'source': 'data\\\\tcs.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3', 'source_file': 'tcs.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 Vision: A leader’s vision provides direcƟon and purpose for their team. \\n\\uf0b7 Adaptability: Leaders must adapt to evolving situaƟons and challenges. \\n\\uf0b7 Inﬂuence: InﬂuenƟal leaders inspire others to follow their lead willingly. \\n\\uf0b7 Respect: Respect for all team members, regardless of their role or background, \\nis essenƟal for creaƟng a harmonious and inclusive workplace. \\nWhere do you see yourself in ﬁve years? \\n\"Over the next five years, I want to become an expert in [mention a key area that \\nrelates to the job].  \\nI hope to take a leadership role within the department, share my knowledge, and \\nhelp the company grow. I see myself as an integral part of the team\\'s success.\"')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bde24ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 9 texts...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m texts=[doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## Generate the Embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m embeddings=\u001b[43membedding_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m##store int he vector dtaabase\u001b[39;00m\n\u001b[32m      9\u001b[39m vectorstore.add_documents(chunks,embeddings)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mEmbeddingManager.generate_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m texts...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# OpenAIEmbeddings returns a list of lists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m embeddings = np.array(embeddings)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated embeddings with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    590\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    483\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\RAG\\rag\\venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498acd10",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351730b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x20f586296a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7e78529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Pritam Sarkar?'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Pritam Sarkar?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23783e",
   "metadata": {},
   "source": [
    "### RAG Pipeline- VectorDB To LLM Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "449a65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba4b617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40bba05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqLLM:\n",
    "    def __init__(self, model_name: str = \"gpt-4o\", api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize Groq LLM\n",
    "\n",
    "        Args:\n",
    "            model_name: Groq model name (qwen2-72b-instruct, llama3-70b-8192, etc.)\n",
    "            api_key: Groq API key (or set GROQ_API_KEY environment variable)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\n",
    "                \"Groq API key is required. Set GROQ_API_KEY environment variable or pass api_key parameter.\"\n",
    "            )\n",
    "\n",
    "        # self.llm = ChatGroq(\n",
    "        #     groq_api_key=self.api_key,\n",
    "        #     model_name=self.model_name,\n",
    "        #     temperature=0.1,\n",
    "        #     max_tokens=1024\n",
    "        # )\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=self.model_name,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1024,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "            api_key=self.api_key,  # if you prefer to pass api key in directly instaed of using env vars\n",
    "            # base_url=\"...\",\n",
    "            # organization=\"...\",\n",
    "            # other params...\n",
    "        )\n",
    "\n",
    "        print(f\"Initialized Groq LLM with model: {self.model_name}\")\n",
    "\n",
    "    def generate_response(self, query: str, context: str, max_length: int = 500) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using retrieved context\n",
    "\n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved document context\n",
    "            max_length: Maximum response length\n",
    "\n",
    "        Returns:\n",
    "            Generated response string\n",
    "        \"\"\"\n",
    "\n",
    "        # Create prompt template\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\"You are a helpful AI assistant. Use the following context to answer the question accurately and concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: Provide a clear and informative answer based on the context above. If the context doesn't contain enough information to answer the question, say so.\"\"\",\n",
    "        )\n",
    "\n",
    "        # Format the prompt\n",
    "        formatted_prompt = prompt_template.format(context=context, question=query)\n",
    "\n",
    "        try:\n",
    "            # Generate response\n",
    "            messages = [HumanMessage(content=formatted_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "    def generate_response_simple(self, query: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Simple response generation without complex prompting\n",
    "\n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved context\n",
    "\n",
    "        Returns:\n",
    "            Generated response\n",
    "        \"\"\"\n",
    "        simple_prompt = f\"\"\"Based on this context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "        try:\n",
    "            messages = [HumanMessage(content=simple_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1fc0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Groq LLM with model: gpt-4o\n",
      "Groq LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq LLM (you'll need to set GROQ_API_KEY environment variable)\n",
    "try:\n",
    "    groq_llm = GroqLLM(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    print(\"Groq LLM initialized successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"Please set your GROQ_API_KEY environment variable to use the LLM.\")\n",
    "    groq_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4110c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Unified Multi-task Learning Framework'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get the context from the retriever and pass it to the LLM\n",
    "\n",
    "rag_retriever.retrieve(\"Unified Multi-task Learning Framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea465ac",
   "metadata": {},
   "source": [
    "### Integration Vectordb Context pipeline With LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a950a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "# from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (set your GROQ_API_KEY in environment)\n",
    "groq_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-it\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=1024,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "            api_key=groq_api_key,  # if you prefer to pass api key in directly instaed of using env vars\n",
    "            # base_url=\"...\",\n",
    "            # organization=\"...\",\n",
    "            # other params...\n",
    "        )\n",
    "\n",
    "## 2. Simple RAG function: retrieve context + generate response\n",
    "def rag_simple(query,retriever,llm,top_k=3):\n",
    "    ## retriever the context\n",
    "    results=retriever.retrieve(query,top_k=top_k)\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    \n",
    "    ## generate the answwer using GROQ LLM\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response=llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df1bf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Who is Pritam Sarkar?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n",
      "No relevant context found to answer the question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"Who is Pritam Sarkar?\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857b1c2",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2832fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Hard Negative Mining Technqiues'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The text describes several hard negative mining techniques used in contrastive learning for retrieval models:\n",
      "\n",
      "* **ANCE:** Uses asynchronous ANN indexing and checkpoint states to periodically update hard negatives.\n",
      "* **Conan-Embedding:** Employs a dynamic strategy, excluding and refreshing samples based on score thresholds.\n",
      "* **NV-Retriever:**  Proposes positive-aware mining with TopK-MarginPos and TopKPercPos filtering to reduce false negatives.\n",
      "* **LGAI-Embedding:** Builds on NV-Retriever, using ANNA IR as a teacher model to identify high-quality hard negatives and TopKPercPos filtering. \n",
      "\n",
      "\n",
      "\n",
      "Sources: [{'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}, {'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}, {'source': 'emneddings.pdf', 'page': 4, 'score': 0.18709993362426758, 'preview': 'QZhou-Embedding Technical Report\\n Kingsoft AI\\n2.4 Hard Negative Mining Techniques\\nHard negatives serve as essential components in contrastive lear ning for retrieval model\\ntraining. Early work like ANCE[\\n46] proposed an asynchronous ANN indexing mech-\\nanism that periodically updates hard negatives u...'}]\n",
      "Confidence: 0.18709993362426758\n",
      "Context Preview: QZhou-Embedding Technical Report\n",
      " Kingsoft AI\n",
      "2.4 Hard Negative Mining Techniques\n",
      "Hard negatives serve as essential components in contrastive lear ning for retrieval model\n",
      "training. Early work like ANCE[\n",
      "46] proposed an asynchronous ANN indexing mech-\n",
      "anism that periodically updates hard negatives u\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Hard Negative Mining Technqiues\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa6150d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is attention is all you need'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention functi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "Question: what is attention is all you need\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: \"Attention Is All You Need\" is a paper that introduced the Transformer model, which relies solely on attention mechanisms for sequence transduction tasks, eliminating the need for recurrent or convolutional networks.  \n",
      "\n",
      "\n",
      "Citations:\n",
      "[1] attention.pdf (page 2)\n",
      "[2] attention.pdf (page 2)\n",
      "[3] attention.pdf (page 2)\n",
      "Summary: The paper \"Attention Is All You Need\" introduced the Transformer model, a novel architecture for sequence transduction tasks.  This model utilizes only attention mechanisms, dispensing with traditional recurrent or convolutional networks. \n",
      "\n",
      "\n",
      "\n",
      "History: {'question': 'what is attention is all you need', 'answer': '\"Attention Is All You Need\" is a paper that introduced the Transformer model, which relies solely on attention mechanisms for sequence transduction tasks, eliminating the need for recurrent or convolutional networks.  \\n', 'sources': [{'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}, {'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}, {'source': 'attention.pdf', 'page': 2, 'score': 0.1399550437927246, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}], 'summary': 'The paper \"Attention Is All You Need\" introduced the Transformer model, a novel architecture for sequence transduction tasks.  This model utilizes only attention mechanisms, dispensing with traditional recurrent or convolutional networks. \\n\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is attention is all you need\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
